{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.0035938903863432167,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 5.989817310572028e-05,
      "grad_norm": 0.7491661310195923,
      "learning_rate": 0.0,
      "loss": 3.4216,
      "step": 1
    },
    {
      "epoch": 0.00011979634621144055,
      "grad_norm": 0.7726593613624573,
      "learning_rate": 4e-05,
      "loss": 3.5159,
      "step": 2
    },
    {
      "epoch": 0.00017969451931716083,
      "grad_norm": 0.877312421798706,
      "learning_rate": 8e-05,
      "loss": 3.6119,
      "step": 3
    },
    {
      "epoch": 0.0002395926924228811,
      "grad_norm": 0.9698398113250732,
      "learning_rate": 0.00012,
      "loss": 3.4214,
      "step": 4
    },
    {
      "epoch": 0.0002994908655286014,
      "grad_norm": 1.0636619329452515,
      "learning_rate": 0.00016,
      "loss": 3.3509,
      "step": 5
    },
    {
      "epoch": 0.00035938903863432165,
      "grad_norm": 1.0657047033309937,
      "learning_rate": 0.0002,
      "loss": 3.1328,
      "step": 6
    },
    {
      "epoch": 0.0004192872117400419,
      "grad_norm": 0.7387380599975586,
      "learning_rate": 0.00019636363636363636,
      "loss": 2.9523,
      "step": 7
    },
    {
      "epoch": 0.0004791853848457622,
      "grad_norm": 0.5549113154411316,
      "learning_rate": 0.00019272727272727274,
      "loss": 2.8806,
      "step": 8
    },
    {
      "epoch": 0.0005390835579514825,
      "grad_norm": 0.4029961824417114,
      "learning_rate": 0.0001890909090909091,
      "loss": 2.8246,
      "step": 9
    },
    {
      "epoch": 0.0005989817310572028,
      "grad_norm": 0.32077884674072266,
      "learning_rate": 0.00018545454545454545,
      "loss": 2.836,
      "step": 10
    },
    {
      "epoch": 0.000658879904162923,
      "grad_norm": 0.33651283383369446,
      "learning_rate": 0.00018181818181818183,
      "loss": 2.8043,
      "step": 11
    },
    {
      "epoch": 0.0007187780772686433,
      "grad_norm": 0.3359387218952179,
      "learning_rate": 0.0001781818181818182,
      "loss": 2.7499,
      "step": 12
    },
    {
      "epoch": 0.0007786762503743636,
      "grad_norm": 0.3447752892971039,
      "learning_rate": 0.00017454545454545454,
      "loss": 2.7867,
      "step": 13
    },
    {
      "epoch": 0.0008385744234800838,
      "grad_norm": 0.326690673828125,
      "learning_rate": 0.0001709090909090909,
      "loss": 2.7123,
      "step": 14
    },
    {
      "epoch": 0.0008984725965858042,
      "grad_norm": 0.37058961391448975,
      "learning_rate": 0.00016727272727272728,
      "loss": 2.7579,
      "step": 15
    },
    {
      "epoch": 0.0009583707696915244,
      "grad_norm": 0.29334139823913574,
      "learning_rate": 0.00016363636363636366,
      "loss": 2.8206,
      "step": 16
    },
    {
      "epoch": 0.0010182689427972447,
      "grad_norm": 0.2717641592025757,
      "learning_rate": 0.00016,
      "loss": 2.7976,
      "step": 17
    },
    {
      "epoch": 0.001078167115902965,
      "grad_norm": 0.24589158594608307,
      "learning_rate": 0.00015636363636363637,
      "loss": 2.6968,
      "step": 18
    },
    {
      "epoch": 0.0011380652890086852,
      "grad_norm": 0.2773208022117615,
      "learning_rate": 0.00015272727272727275,
      "loss": 2.7272,
      "step": 19
    },
    {
      "epoch": 0.0011979634621144056,
      "grad_norm": 0.25318220257759094,
      "learning_rate": 0.0001490909090909091,
      "loss": 2.6146,
      "step": 20
    },
    {
      "epoch": 0.0012578616352201257,
      "grad_norm": 0.27406370639801025,
      "learning_rate": 0.00014545454545454546,
      "loss": 2.9234,
      "step": 21
    },
    {
      "epoch": 0.001317759808325846,
      "grad_norm": 0.2509319484233856,
      "learning_rate": 0.00014181818181818184,
      "loss": 2.6686,
      "step": 22
    },
    {
      "epoch": 0.0013776579814315662,
      "grad_norm": 0.2244819551706314,
      "learning_rate": 0.0001381818181818182,
      "loss": 2.5023,
      "step": 23
    },
    {
      "epoch": 0.0014375561545372866,
      "grad_norm": 0.23078085482120514,
      "learning_rate": 0.00013454545454545455,
      "loss": 2.6711,
      "step": 24
    },
    {
      "epoch": 0.001497454327643007,
      "grad_norm": 0.2646026015281677,
      "learning_rate": 0.00013090909090909093,
      "loss": 2.53,
      "step": 25
    },
    {
      "epoch": 0.0015573525007487271,
      "grad_norm": 449.7790832519531,
      "learning_rate": 0.00012727272727272728,
      "loss": 2.6278,
      "step": 26
    },
    {
      "epoch": 0.0016172506738544475,
      "grad_norm": 0.2362346053123474,
      "learning_rate": 0.00012363636363636364,
      "loss": 2.5308,
      "step": 27
    },
    {
      "epoch": 0.0016771488469601676,
      "grad_norm": 0.23036298155784607,
      "learning_rate": 0.00012,
      "loss": 2.5477,
      "step": 28
    },
    {
      "epoch": 0.001737047020065888,
      "grad_norm": 0.2244684398174286,
      "learning_rate": 0.00011636363636363636,
      "loss": 2.6226,
      "step": 29
    },
    {
      "epoch": 0.0017969451931716084,
      "grad_norm": 0.25818541646003723,
      "learning_rate": 0.00011272727272727272,
      "loss": 2.5199,
      "step": 30
    },
    {
      "epoch": 0.0018568433662773285,
      "grad_norm": 0.2678723633289337,
      "learning_rate": 0.00010909090909090909,
      "loss": 2.615,
      "step": 31
    },
    {
      "epoch": 0.0019167415393830489,
      "grad_norm": 0.24287034571170807,
      "learning_rate": 0.00010545454545454545,
      "loss": 2.6001,
      "step": 32
    },
    {
      "epoch": 0.001976639712488769,
      "grad_norm": 0.21675743162631989,
      "learning_rate": 0.00010181818181818181,
      "loss": 2.5825,
      "step": 33
    },
    {
      "epoch": 0.0020365378855944894,
      "grad_norm": 0.22969019412994385,
      "learning_rate": 9.818181818181818e-05,
      "loss": 2.6027,
      "step": 34
    },
    {
      "epoch": 0.0020964360587002098,
      "grad_norm": 0.2248358279466629,
      "learning_rate": 9.454545454545455e-05,
      "loss": 2.6615,
      "step": 35
    },
    {
      "epoch": 0.00215633423180593,
      "grad_norm": 0.2353842705488205,
      "learning_rate": 9.090909090909092e-05,
      "loss": 2.4875,
      "step": 36
    },
    {
      "epoch": 0.00221623240491165,
      "grad_norm": 0.2201840728521347,
      "learning_rate": 8.727272727272727e-05,
      "loss": 2.6331,
      "step": 37
    },
    {
      "epoch": 0.0022761305780173704,
      "grad_norm": 0.2234414964914322,
      "learning_rate": 8.363636363636364e-05,
      "loss": 2.5991,
      "step": 38
    },
    {
      "epoch": 0.002336028751123091,
      "grad_norm": 0.21450304985046387,
      "learning_rate": 8e-05,
      "loss": 2.5726,
      "step": 39
    },
    {
      "epoch": 0.002395926924228811,
      "grad_norm": 0.22772395610809326,
      "learning_rate": 7.636363636363637e-05,
      "loss": 2.4579,
      "step": 40
    },
    {
      "epoch": 0.002455825097334531,
      "grad_norm": 0.20987653732299805,
      "learning_rate": 7.272727272727273e-05,
      "loss": 2.5858,
      "step": 41
    },
    {
      "epoch": 0.0025157232704402514,
      "grad_norm": 0.20037536323070526,
      "learning_rate": 6.90909090909091e-05,
      "loss": 2.3848,
      "step": 42
    },
    {
      "epoch": 0.002575621443545972,
      "grad_norm": 0.21758678555488586,
      "learning_rate": 6.545454545454546e-05,
      "loss": 2.5344,
      "step": 43
    },
    {
      "epoch": 0.002635519616651692,
      "grad_norm": 0.21354985237121582,
      "learning_rate": 6.181818181818182e-05,
      "loss": 2.5933,
      "step": 44
    },
    {
      "epoch": 0.0026954177897574125,
      "grad_norm": 0.250428706407547,
      "learning_rate": 5.818181818181818e-05,
      "loss": 2.4592,
      "step": 45
    },
    {
      "epoch": 0.0027553159628631325,
      "grad_norm": 0.22186502814292908,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 2.5585,
      "step": 46
    },
    {
      "epoch": 0.002815214135968853,
      "grad_norm": 0.24662365019321442,
      "learning_rate": 5.090909090909091e-05,
      "loss": 2.5099,
      "step": 47
    },
    {
      "epoch": 0.002875112309074573,
      "grad_norm": 0.221278578042984,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 2.4408,
      "step": 48
    },
    {
      "epoch": 0.0029350104821802936,
      "grad_norm": 0.22902189195156097,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 2.5063,
      "step": 49
    },
    {
      "epoch": 0.002994908655286014,
      "grad_norm": 0.24357856810092926,
      "learning_rate": 4e-05,
      "loss": 2.3641,
      "step": 50
    },
    {
      "epoch": 0.003054806828391734,
      "grad_norm": 0.23281531035900116,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 2.5723,
      "step": 51
    },
    {
      "epoch": 0.0031147050014974542,
      "grad_norm": 0.21656179428100586,
      "learning_rate": 3.272727272727273e-05,
      "loss": 2.4975,
      "step": 52
    },
    {
      "epoch": 0.0031746031746031746,
      "grad_norm": 0.231777161359787,
      "learning_rate": 2.909090909090909e-05,
      "loss": 2.3678,
      "step": 53
    },
    {
      "epoch": 0.003234501347708895,
      "grad_norm": 0.22745074331760406,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 2.4996,
      "step": 54
    },
    {
      "epoch": 0.0032943995208146153,
      "grad_norm": 0.22156046330928802,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 2.508,
      "step": 55
    },
    {
      "epoch": 0.0033542976939203353,
      "grad_norm": 0.21930521726608276,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 2.5901,
      "step": 56
    },
    {
      "epoch": 0.0034141958670260556,
      "grad_norm": 0.2189704328775406,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 2.4715,
      "step": 57
    },
    {
      "epoch": 0.003474094040131776,
      "grad_norm": 0.21848952770233154,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 2.4664,
      "step": 58
    },
    {
      "epoch": 0.0035339922132374964,
      "grad_norm": 0.2829011082649231,
      "learning_rate": 7.272727272727272e-06,
      "loss": 2.612,
      "step": 59
    },
    {
      "epoch": 0.0035938903863432167,
      "grad_norm": 0.22637076675891876,
      "learning_rate": 3.636363636363636e-06,
      "loss": 2.7308,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6877614463229952.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
